{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface\n",
    "\n",
    "- **Simplifying Custom Chain Creation with Runnable Protocol**:\n",
    "  - LangChain introduces the \"Runnable\" protocol to facilitate the creation and invocation of custom chains.\n",
    "  - This protocol is implemented in most components, offering a standard interface for both defining and invoking chains.\n",
    "\n",
    "- **Standard Interface Methods**:\n",
    "  1. **Synchronous Methods**:\n",
    "     - `stream`: Streams back chunks of the response.\n",
    "     - `invoke`: Calls the chain on an input.\n",
    "     - `batch`: Processes a list of inputs through the chain.\n",
    "  2. **Asynchronous Methods**:\n",
    "     - `astream`: Asynchronously streams back response chunks.\n",
    "     - `ainvoke`: Asynchronously calls the chain on an input.\n",
    "     - `abatch`: Asynchronously processes a list of inputs.\n",
    "     - `astream_log`: Streams back intermediate steps and the final response.\n",
    "\n",
    "- **Input and Output Types by Component**:\n",
    "  | Component      | Input Type                                  | Output Type       |\n",
    "  | -------------- | ------------------------------------------- | ----------------- |\n",
    "  | Prompt         | Dictionary                                  | PromptValue       |\n",
    "  | ChatModel      | Single string, list of messages, PromptValue | ChatMessage      |\n",
    "  | LLM            | Single string, list of messages, PromptValue | String            |\n",
    "  | OutputParser   | LLM/ChatModel output                        | Varies            |\n",
    "  | Retriever      | Single string                               | List of Documents |\n",
    "  | Tool           | String or dictionary                        | Varies            |\n",
    "\n",
    "- **Input and Output Schemas**:\n",
    "  - All runnables feature auto-generated Pydantic models for inputs (`input_schema`) and outputs (`output_schema`), based on their structure.\n",
    "\n",
    "- **Practical Example**:\n",
    "  - To understand these methods, a basic `PromptTemplate + ChatModel` chain can be created and examined.\n",
    "\n",
    "- **Runnable Schemas in LangChain**:\n",
    "  - All Runnable components in LangChain provide schemas for input and output inspection:\n",
    "    - `input_schema`: An auto-generated Pydantic model reflecting the structure of the Runnable, used for input validation.\n",
    "    - `output_schema`: A similar auto-generated Pydantic model for the Runnable's output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIInput',\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/definitions/StringPromptValue'},\n",
       "  {'$ref': '#/definitions/ChatPromptValueConcrete'},\n",
       "  {'type': 'array',\n",
       "   'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "     {'$ref': '#/definitions/HumanMessage'},\n",
       "     {'$ref': '#/definitions/ChatMessage'},\n",
       "     {'$ref': '#/definitions/SystemMessage'},\n",
       "     {'$ref': '#/definitions/FunctionMessage'},\n",
       "     {'$ref': '#/definitions/ToolMessage'}]}}],\n",
       " 'definitions': {'StringPromptValue': {'title': 'StringPromptValue',\n",
       "   'description': 'String prompt value.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'StringPromptValue',\n",
       "     'enum': ['StringPromptValue'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'A Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'A Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'A Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'A Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'A Message for passing the result of executing a tool back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']},\n",
       "  'ChatPromptValueConcrete': {'title': 'ChatPromptValueConcrete',\n",
       "   'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\nFor use in external schemas.',\n",
       "   'type': 'object',\n",
       "   'properties': {'messages': {'title': 'Messages',\n",
       "     'type': 'array',\n",
       "     'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "       {'$ref': '#/definitions/HumanMessage'},\n",
       "       {'$ref': '#/definitions/ChatMessage'},\n",
       "       {'$ref': '#/definitions/SystemMessage'},\n",
       "       {'$ref': '#/definitions/FunctionMessage'},\n",
       "       {'$ref': '#/definitions/ToolMessage'}]}},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'enum': ['ChatPromptValueConcrete'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages']}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output schema\n",
    "\n",
    "- **Runnable Output Descriptions in LangChain**:\n",
    "  - The output produced by a Runnable is defined through a Pydantic model.\n",
    "  - This model is dynamically generated based on the structure of the Runnable.\n",
    "  - To access a JSONSchema representation of this output, one can use the `.schema()` method on the Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIOutput',\n",
       " 'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "  {'$ref': '#/definitions/HumanMessage'},\n",
       "  {'$ref': '#/definitions/ChatMessage'},\n",
       "  {'$ref': '#/definitions/SystemMessage'},\n",
       "  {'$ref': '#/definitions/FunctionMessage'},\n",
       "  {'$ref': '#/definitions/ToolMessage'}],\n",
       " 'definitions': {'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'A Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'A Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'A Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'A Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'A Message for passing the result of executing a tool back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't bears wear shoes?\n",
      "\n",
      "Because they already have bear feet!"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "  print(s.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't bears wear shoes?\\n\\nBecause they already have bear feet!\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "  {\n",
    "    \"topic\": \"bears\"\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why don't bears wear shoes?\\n\\nBecause they already have bear feet!\"),\n",
       " AIMessage(content=\"Sure, here's a joke about cats:\\n\\nWhy don't cats play poker in the wild?\\n\\nToo many cheetahs!\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(\n",
    "  [\n",
    "    {\n",
    "      \"topic\": \"bears\"\n",
    "    },\n",
    "    {\n",
    "      \"topic\": \"cats\"\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why don't bears ever wear shoes?\\n\\nBecause they have bear feet!\"),\n",
       " AIMessage(content=\"Sure, here's a cat-themed joke for you:\\n\\nWhy don't cats play poker in the wild?\\n\\nBecause they're afraid of cheetahs!\"),\n",
       " AIMessage(content=\"Sure, here's a bird joke for you:\\n\\nWhy don't seagulls fly over the bay?\\n\\nBecause then they would be bagels!\"),\n",
       " AIMessage(content=\"Why don't snakes ever take time off work?\\n\\nBecause they don't like to hiss-tory!\"),\n",
       " AIMessage(content=\"Why don't monkeys play cards in the wild?\\n\\nBecause there are too many cheetahs!\")]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also structure the chain like following\n",
    "# Then, no need to provide dictionaries\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain_v2 = { \"topic\": RunnablePassthrough()} | prompt | model\n",
    "\n",
    "chain_v2.batch(\n",
    "  [\n",
    "    \"bears\",\n",
    "    \"cats\",\n",
    "    \"birds\",\n",
    "    \"snakes\",\n",
    "    \"monkeys\"\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the bear bring a ladder to the party?\n",
      "\n",
      "Because he wanted to \"raise\" the roof!"
     ]
    }
   ],
   "source": [
    "async for s in chain.astream({\"topic\": \"bears\"}):\n",
    "  print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't bears wear shoes?\\n\\nBecause they have bear feet!\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.ainvoke(\n",
    "  {\n",
    "    \"topic\": \"bears\"\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Why did the bellman take up singing?\\n\\nBecause he wanted to be a bell-canto!'),\n",
       " AIMessage(content='Why did the ice cream go to therapy?\\n\\nBecause it had too many meltdowns!'),\n",
       " AIMessage(content='Why did the car go to therapy?\\nBecause it had too many breakdowns!'),\n",
       " AIMessage(content='Why did the girl bring a ladder to the bar?\\n\\nBecause she heard the drinks were on the house!'),\n",
       " AIMessage(content='Why did the computer go to art school?\\n\\nBecause it had a lot of hard drive!'),\n",
       " AIMessage(content=\"Why did the Earth break up with the Moon? \\n\\nBecause it couldn't resist its gravitational pull!\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain_v2.abatch(\n",
    "  [\n",
    "    \"bellman\",\n",
    "    \"ice cream\",\n",
    "    \"cars\",\n",
    "    \"girls\",\n",
    "    \"computers\",\n",
    "    \"earth\"\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async Stream Intermediate Steps\n",
    "\n",
    "- **Intermediate Step Streaming in Runnables**:\n",
    "  - LangChain Runnables feature the `.astream_log()` method, allowing for streaming of intermediate steps in real-time.\n",
    "  - This functionality is beneficial for several purposes:\n",
    "    - Showing progress to the user.\n",
    "    - Utilizing intermediate results.\n",
    "    - Debugging the chain.\n",
    "  - Users have the flexibility to stream all steps by default or to selectively include/exclude steps based on name, tags, or metadata.\n",
    "\n",
    "- **Streaming Output Format**:\n",
    "  - The `.astream_log()` method produces JSONPatch operations.\n",
    "  - These operations, when applied in sequence, construct the RunState, offering a comprehensive view of the chain's progress and intermediate states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional, Any, Dict\n",
    "\n",
    "class LogEntry(TypedDict):\n",
    "\n",
    "    id: str\n",
    "    \"\"\"ID of the sub-run.\"\"\"\n",
    "    name: str\n",
    "    \"\"\"Name of the object being run.\"\"\"\n",
    "    type: str\n",
    "    \"\"\"Type of the object being run, eg. prompt, chain, llm, etc.\"\"\"\n",
    "    tags: List[str]\n",
    "    \"\"\"List of tags for the run.\"\"\"\n",
    "    metadata: Dict[str, Any]\n",
    "    \"\"\"Key-value pairs of metadata for the run.\"\"\"\n",
    "    start_time: str\n",
    "    \"\"\"ISO-8601 timestamp of when the run started.\"\"\"\n",
    "\n",
    "    streamed_output_str: List[str]\n",
    "    \"\"\"List of LLM tokens streamed by this run, if applicable.\"\"\"\n",
    "    final_output: Optional[Any]\n",
    "    \"\"\"Final output of this run.\n",
    "    Only available after the run has finished successfully.\"\"\"\n",
    "    end_time: Optional[str]\n",
    "    \"\"\"ISO-8601 timestamp of when the run ended.\n",
    "    Only available after the run has finished.\"\"\"\n",
    "\n",
    "\n",
    "class RunState(TypedDict):\n",
    "    id: str\n",
    "    \"\"\"ID of the run.\"\"\"\n",
    "    streamed_output: List[Any]\n",
    "    \"\"\"List of output chunks streamed by Runnable.stream()\"\"\"\n",
    "    final_output: Optional[Any]\n",
    "    \"\"\"Final output of the run, usually the result of aggregating (`+`) streamed_output.\n",
    "    Only available after the run has finished successfully.\"\"\"\n",
    "\n",
    "    logs: Dict[str, LogEntry]\n",
    "    \"\"\"Map of run names to sub-runs. If filters were supplied, this list will\n",
    "    contain only the runs that matched the filters.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming JSONPatch chunks\n",
    "\n",
    "- **Streaming JSONPatch in HTTP Servers**:\n",
    "  - The capability to stream JSONPatch operations from Runnables is particularly useful in web applications.\n",
    "  - This streaming can be employed in HTTP servers, allowing the client-side to receive and apply these operations.\n",
    "\n",
    "- **Client-Side Application**:\n",
    "  - By applying the streamed JSONPatch operations on the client side, it's possible to rebuild and replicate the run state as it evolves.\n",
    "\n",
    "- **LangServe Integration**:\n",
    "  - LangChain's LangServe offers specialized tools to simplify the creation of a webserver from any Runnable, enhancing the ease of integrating this streaming capability into web applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the question based only on the following context: {context}.\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "vectorstore = FAISS.from_texts([\"harrison worked at kensho\"], embedding=OpenAIEmbeddings())\n",
    "retreiver = vectorstore.as_retriever()\n",
    "\n",
    "retrieval_chain = (\n",
    "  {\n",
    "    \"context\": retreiver.with_config(run_name=\"Docs\"),\n",
    "    \"question\": RunnablePassthrough()\n",
    "  }\n",
    "  | prompt\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': 'c7f8162f-832d-4009-aa08-f725b01939c7',\n",
      "            'logs': {},\n",
      "            'streamed_output': []}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '294ac588-c890-4c05-8a9a-00593212ac97',\n",
      "            'metadata': {},\n",
      "            'name': 'Docs',\n",
      "            'start_time': '2023-12-17T12:33:50.727',\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "            'type': 'retriever'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs/final_output',\n",
      "  'value': {'documents': [Document(page_content='harrison worked at kensho')]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/Docs/end_time',\n",
      "  'value': '2023-12-17T12:33:51.034'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ''},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': ''})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'H'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'H'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'arrison'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'Harrison'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' worked'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'Harrison worked'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' at'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'Harrison worked at'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Kens'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'Harrison worked at Kens'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'ho'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'Harrison worked at Kensho'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'Harrison worked at Kensho.'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ''})\n"
     ]
    }
   ],
   "source": [
    "async for chunk in retrieval_chain.astream_log(\"where did harrison work?\", include_names=[\"Docs\"]):\n",
    "  print(\"-\" * 40)\n",
    "  print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamijng the incremental RunState\n",
    "\n",
    "- **Streaming Incremental RunState**:\n",
    "  - To obtain incremental values of RunState in a more verbose and detailed format, you can set `diff=False` in the streaming process.\n",
    "  - This approach results in an output that includes more repetitive parts, providing a comprehensive view of each stage in the RunState."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {},\n",
      " 'streamed_output': []})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': None,\n",
      "                   'final_output': None,\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': []})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': []})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': '',\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': ['']})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': 'H',\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H']})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': 'Harrison',\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison']})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': 'Harrison worked',\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked']})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': 'Harrison worked at',\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked', ' at']})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': 'Harrison worked at Kens',\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked', ' at', ' Kens']})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': 'Harrison worked at Kensho',\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked', ' at', ' Kens', 'ho']})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': 'Harrison worked at Kensho.',\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked', ' at', ' Kens', 'ho', '.']})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': 'Harrison worked at Kensho.',\n",
      " 'id': '4be41e15-e758-457e-88c3-55f93ece8fbf',\n",
      " 'logs': {'Docs': {'end_time': '2023-12-17T12:37:12.007',\n",
      "                   'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                   'id': '8c8a5ba7-80d2-4443-ad59-0017386fa3d2',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2023-12-17T12:37:11.723',\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'streamed_output': ['',\n",
      "                     'H',\n",
      "                     'arrison',\n",
      "                     ' worked',\n",
      "                     ' at',\n",
      "                     ' Kens',\n",
      "                     'ho',\n",
      "                     '.',\n",
      "                     '']})\n"
     ]
    }
   ],
   "source": [
    "async for chunk in retrieval_chain.astream_log(\n",
    "    \"where did harrison work?\", include_names=[\"Docs\"], diff=False\n",
    "):\n",
    "    print(\"-\" * 70)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parrarellism\n",
    "\n",
    "- **Parallelism in LangChain Expression Language**:\n",
    "  - LangChain Expression Language (LCEL) facilitates parallel processing of requests.\n",
    "  - Using `RunnableParallel`, often represented as a dictionary, allows for simultaneous execution of each element in the dictionary.\n",
    "  - This feature is particularly useful for tasks that can benefit from concurrent operations, enhancing efficiency and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model\n",
    "chain2 = (\n",
    "    ChatPromptTemplate.from_template(\"write a short (2 line) poem about {topic}\")\n",
    "    | model\n",
    ")\n",
    "combined = RunnableParallel(joke=chain1, poem=chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.62 ms, sys: 2.17 ms, total: 8.79 ms\n",
      "Wall time: 655 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure, here's a bear joke for you:\\n\\nWhy don't bears wear shoes?\\n\\nBecause they already have bear feet!\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chain1.invoke(\n",
    "  {\n",
    "    \"topic\": \"bears\"\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.06 ms, sys: 1.67 ms, total: 8.73 ms\n",
      "Wall time: 485 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"In forest's embrace,\\nMajestic bears leave their trace.\")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chain2.invoke(\n",
    "  {\n",
    "    \"topic\": \"bears\"\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.4 ms, sys: 4.3 ms, total: 34.7 ms\n",
      "Wall time: 516 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content=\"Why don't bears wear shoes?\\n\\nBecause they have bear feet!\"),\n",
       " 'poem': AIMessage(content=\"In forest's embrace, \\nMajestic bears leave their trace.\")}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "combined.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelism on batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.7 ms, sys: 3.62 ms, total: 32.3 ms\n",
      "Wall time: 645 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why don't bears wear shoes?\\n\\nBecause they have bear feet!\"),\n",
       " AIMessage(content=\"Sure, here's a cat-related joke for you:\\n\\nWhy don't cats play poker in the wild?\\n\\nBecause there are too many cheetahs!\")]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chain1.batch([{\"topic\": \"bears\"}, {\"topic\": \"cats\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.8 ms, sys: 3.72 ms, total: 27.5 ms\n",
      "Wall time: 560 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"In deep woods they roam,\\nMajestic bears, nature's crown.\"),\n",
       " AIMessage(content='Whiskers dance on moonlit trails,\\nSoft purrs weave tales of feline tales.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chain2.batch([{\"topic\": \"bears\"}, {\"topic\": \"cats\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.5 ms, sys: 7.69 ms, total: 62.2 ms\n",
      "Wall time: 507 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'joke': AIMessage(content='Why don\\'t bears use cell phones? \\n\\nBecause they already have \"paws\"ome reception in the woods!'),\n",
       "  'poem': AIMessage(content='In the wild they roam,\\nMajestic bears find their home.')},\n",
       " {'joke': AIMessage(content=\"Why don't cats play poker in the wild?\\n\\nToo many cheetahs!\"),\n",
       "  'poem': AIMessage(content='Whiskers soft, eyes so bright,\\nCats bring joy, day and night.')}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "combined.batch([{\"topic\": \"bears\"}, {\"topic\": \"cats\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
